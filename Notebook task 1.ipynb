{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"BDCC1.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"p-eZZoCHTSwk","outputId":"49787619-ee17-4bb2-9659-25a2d25e999f"},"source":["%%file python/task_1.py\n","#Task 1\n","from mrjob.job import MRJob\n","\n","class task_1(MRJob):\n","    def mapper(self, _, line):\n","        columns = line.split()\n","        \n","        follower = int(columns[0])\n","        \n","        followee = int(columns[1])\n","        \n","        yield (followee, follower)\n","        \n","    def reducer(self, followee, follower):\n","        list_of_followers = [follow for follow in follower]\n","        yield (followee, list_of_followers)\n","        \n","if __name__ == '__main__':\n","    task_1.run()   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting python/task_1.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Agbp9QtmTSwn","outputId":"e3be292f-f9de-45b2-bd2d-a88596af2254"},"source":["!python3 python/task_1.py data/graph.txt -o out/list_of_followers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No configs found; falling back on auto-configuration\n","No configs specified for inline runner\n","Running step 1 of 1...\n","Creating temp directory /tmp/task_1.bdccuser.20210611.173833.561949\n","job output is in out/list_of_followers\n","Removing temp directory /tmp/task_1.bdccuser.20210611.173833.561949...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vynnldVITSwo","outputId":"fd3665e5-c918-4779-f565-3e9aa8bb6984"},"source":["!hdfs dfs -rm -r list_of_followers\n","!python3 python/task_1.py -r hadoop data/graph.txt -o list_of_followers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Deleted list_of_followers\n","No configs found; falling back on auto-configuration\n","No configs specified for hadoop runner\n","Looking for hadoop binary in /home/hdoop/hadoop-3.2.1/bin...\n","Found hadoop binary: /home/hdoop/hadoop-3.2.1/bin/hadoop\n","Using Hadoop version 3.2.1\n","Looking for Hadoop streaming jar in /home/hdoop/hadoop-3.2.1...\n","Found Hadoop streaming jar: /home/hdoop/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar\n","Creating temp directory /tmp/task_1.bdccuser.20210611.173928.739611\n","uploading working dir files to hdfs:///user/bdccuser/tmp/mrjob/task_1.bdccuser.20210611.173928.739611/files/wd...\n","Copying other local files to hdfs:///user/bdccuser/tmp/mrjob/task_1.bdccuser.20210611.173928.739611/files/\n","Running step 1 of 1...\n","  packageJobJar: [/tmp/hadoop-unjar4179244746585271916/] [] /tmp/streamjob7824552078418662307.jar tmpDir=null\n","  Connecting to ResourceManager at /127.0.0.1:8032\n","  Connecting to ResourceManager at /127.0.0.1:8032\n","  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/bdccuser/.staging/job_1623429500132_0002\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  Caught exception\n","java.lang.InterruptedException\n","\tat java.lang.Object.wait(Native Method)\n","\tat java.lang.Thread.join(Thread.java:1252)\n","\tat java.lang.Thread.join(Thread.java:1326)\n","\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)\n","\tat org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)\n","\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)\n","  Total input files to process : 1\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  Caught exception\n","java.lang.InterruptedException\n","\tat java.lang.Object.wait(Native Method)\n","\tat java.lang.Thread.join(Thread.java:1252)\n","\tat java.lang.Thread.join(Thread.java:1326)\n","\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)\n","\tat org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)\n","\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)\n","  number of splits:2\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  Submitting tokens for job: job_1623429500132_0002\n","  Executing with tokens: []\n","  resource-types.xml not found\n","  Unable to find 'resource-types.xml'.\n","  Submitted application application_1623429500132_0002\n","  The url to track the job: http://bdcc:8088/proxy/application_1623429500132_0002/\n","  Running job: job_1623429500132_0002\n","  Job job_1623429500132_0002 running in uber mode : false\n","   map 0% reduce 0%\n","   map 13% reduce 0%\n","   map 20% reduce 0%\n","   map 27% reduce 0%\n","   map 35% reduce 0%\n","   map 44% reduce 0%\n","   map 52% reduce 0%\n","   map 61% reduce 0%\n","   map 65% reduce 0%\n","   map 82% reduce 0%\n","   map 83% reduce 0%\n","   map 100% reduce 0%\n","   map 100% reduce 74%\n","   map 100% reduce 79%\n","   map 100% reduce 83%\n","   map 100% reduce 87%\n","   map 100% reduce 92%\n","   map 100% reduce 96%\n","   map 100% reduce 100%\n","  Job job_1623429500132_0002 completed successfully\n","  Output directory: hdfs:///user/bdccuser/list_of_followers\n","Counters: 54\n","\tFile Input Format Counters \n","\t\tBytes Read=38724796\n","\tFile Output Format Counters \n","\t\tBytes Written=30426058\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=44695954\n","\t\tFILE: Number of bytes written=90085705\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of write operations=0\n","\t\tHDFS: Number of bytes read=38725100\n","\t\tHDFS: Number of bytes read erasure-coded=0\n","\t\tHDFS: Number of bytes written=30426058\n","\t\tHDFS: Number of large read operations=0\n","\t\tHDFS: Number of read operations=11\n","\t\tHDFS: Number of write operations=2\n","\tJob Counters \n","\t\tData-local map tasks=2\n","\t\tLaunched map tasks=2\n","\t\tLaunched reduce tasks=1\n","\t\tTotal megabyte-milliseconds taken by all map tasks=133573632\n","\t\tTotal megabyte-milliseconds taken by all reduce tasks=56935424\n","\t\tTotal time spent by all map tasks (ms)=130443\n","\t\tTotal time spent by all maps in occupied slots (ms)=130443\n","\t\tTotal time spent by all reduce tasks (ms)=55601\n","\t\tTotal time spent by all reduces in occupied slots (ms)=55601\n","\t\tTotal vcore-milliseconds taken by all map tasks=130443\n","\t\tTotal vcore-milliseconds taken by all reduce tasks=55601\n","\tMap-Reduce Framework\n","\t\tCPU time spent (ms)=98770\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tFailed Shuffles=0\n","\t\tGC time elapsed (ms)=553\n","\t\tInput split bytes=304\n","\t\tMap input records=2987624\n","\t\tMap output bytes=38720700\n","\t\tMap output materialized bytes=44695960\n","\t\tMap output records=2987624\n","\t\tMerged Map outputs=2\n","\t\tPeak Map Physical memory (bytes)=243212288\n","\t\tPeak Map Virtual memory (bytes)=2527473664\n","\t\tPeak Reduce Physical memory (bytes)=192368640\n","\t\tPeak Reduce Virtual memory (bytes)=2535174144\n","\t\tPhysical memory (bytes) snapshot=607559680\n","\t\tReduce input groups=1134140\n","\t\tReduce input records=2987624\n","\t\tReduce output records=1134140\n","\t\tReduce shuffle bytes=44695960\n","\t\tShuffled Maps =2\n","\t\tSpilled Records=5975248\n","\t\tTotal committed heap usage (bytes)=432381952\n","\t\tVirtual memory (bytes) snapshot=7457796096\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","job output is in hdfs:///user/bdccuser/list_of_followers\n","Removing HDFS temp directory hdfs:///user/bdccuser/tmp/mrjob/task_1.bdccuser.20210611.173928.739611...\n","Removing temp directory /tmp/task_1.bdccuser.20210611.173928.739611...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"maBKVXI4TSwo","outputId":"945d9aa5-9e3e-4624-a214-cb4cd8a1c451"},"source":["!hdfs dfs -copyToLocal list_of_followers /home/bdccuser/notebooks/mapreduce/out/list_of_followers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-06-11 20:42:11,016 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mVeFc8fbTSwo","outputId":"a7421936-b152-43c3-bc2c-ba071c8008d2"},"source":["%%file python/task_2.py\n","#Task 2\n","\n","from mrjob.job import MRJob\n","\n","class task_2(MRJob):\n","    def mapper(self, _, line):\n","        columns = line.split()\n","        \n","        follower = int(columns[0])\n","        \n","        followee = int(columns[1])\n","        \n","        yield (follower, followee)\n","        \n","\n","    def reducer(self, follower, followee):\n","        list_of_followees = [follow for follow in followee]\n","        yield (follower, list_of_followees)\n","\n","      \n","if __name__ == '__main__':\n","    task_2.run()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting python/task_2.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FA9qmlbJTSwp","outputId":"5ad21f48-451b-4a1e-8384-405c6cdbda03"},"source":["!python3 python/task_2.py data/graph.txt -o out/list_of_followees"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No configs found; falling back on auto-configuration\n","No configs specified for inline runner\n","Running step 1 of 1...\n","Creating temp directory /tmp/task_2.bdccuser.20210611.174212.065251\n","job output is in out/list_of_followees\n","Removing temp directory /tmp/task_2.bdccuser.20210611.174212.065251...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"psDqfi94TSwp","outputId":"c9f4fedb-973a-4fd3-da53-9e88fc63f5dc"},"source":["!hdfs dfs -rm -r list_of_followees\n","!python3 python/task_2.py -r hadoop data/graph.txt -o list_of_followees"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Deleted list_of_followees\n","No configs found; falling back on auto-configuration\n","No configs specified for hadoop runner\n","Looking for hadoop binary in /home/hdoop/hadoop-3.2.1/bin...\n","Found hadoop binary: /home/hdoop/hadoop-3.2.1/bin/hadoop\n","Using Hadoop version 3.2.1\n","Looking for Hadoop streaming jar in /home/hdoop/hadoop-3.2.1...\n","Found Hadoop streaming jar: /home/hdoop/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar\n","Creating temp directory /tmp/task_2.bdccuser.20210611.174303.225147\n","uploading working dir files to hdfs:///user/bdccuser/tmp/mrjob/task_2.bdccuser.20210611.174303.225147/files/wd...\n","Copying other local files to hdfs:///user/bdccuser/tmp/mrjob/task_2.bdccuser.20210611.174303.225147/files/\n","Running step 1 of 1...\n","  packageJobJar: [/tmp/hadoop-unjar6151482047874502450/] [] /tmp/streamjob7815499975299214082.jar tmpDir=null\n","  Connecting to ResourceManager at /127.0.0.1:8032\n","  Connecting to ResourceManager at /127.0.0.1:8032\n","  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/bdccuser/.staging/job_1623429500132_0003\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  Caught exception\n","java.lang.InterruptedException\n","\tat java.lang.Object.wait(Native Method)\n","\tat java.lang.Thread.join(Thread.java:1252)\n","\tat java.lang.Thread.join(Thread.java:1326)\n","\tat org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)\n","\tat org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)\n","\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)\n","  Total input files to process : 1\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  number of splits:2\n","  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n","  Submitting tokens for job: job_1623429500132_0003\n","  Executing with tokens: []\n","  resource-types.xml not found\n","  Unable to find 'resource-types.xml'.\n","  Submitted application application_1623429500132_0003\n","  The url to track the job: http://bdcc:8088/proxy/application_1623429500132_0003/\n","  Running job: job_1623429500132_0003\n","  Job job_1623429500132_0003 running in uber mode : false\n","   map 0% reduce 0%\n","   map 11% reduce 0%\n","   map 18% reduce 0%\n","   map 26% reduce 0%\n","   map 32% reduce 0%\n","   map 39% reduce 0%\n","   map 48% reduce 0%\n","   map 56% reduce 0%\n","   map 62% reduce 0%\n","   map 79% reduce 0%\n","   map 83% reduce 0%\n","   map 100% reduce 0%\n","   map 100% reduce 77%\n","   map 100% reduce 83%\n","   map 100% reduce 90%\n","   map 100% reduce 96%\n","   map 100% reduce 100%\n","  Job job_1623429500132_0003 completed successfully\n","  Output directory: hdfs:///user/bdccuser/list_of_followees\n","Counters: 54\n","\tFile Input Format Counters \n","\t\tBytes Read=38724796\n","\tFile Output Format Counters \n","\t\tBytes Written=26329085\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=44695954\n","\t\tFILE: Number of bytes written=90085705\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of write operations=0\n","\t\tHDFS: Number of bytes read=38725100\n","\t\tHDFS: Number of bytes read erasure-coded=0\n","\t\tHDFS: Number of bytes written=26329085\n","\t\tHDFS: Number of large read operations=0\n","\t\tHDFS: Number of read operations=11\n","\t\tHDFS: Number of write operations=2\n","\tJob Counters \n","\t\tData-local map tasks=2\n","\t\tLaunched map tasks=2\n","\t\tLaunched reduce tasks=1\n","\t\tTotal megabyte-milliseconds taken by all map tasks=144207872\n","\t\tTotal megabyte-milliseconds taken by all reduce tasks=43387904\n","\t\tTotal time spent by all map tasks (ms)=140828\n","\t\tTotal time spent by all maps in occupied slots (ms)=140828\n","\t\tTotal time spent by all reduce tasks (ms)=42371\n","\t\tTotal time spent by all reduces in occupied slots (ms)=42371\n","\t\tTotal vcore-milliseconds taken by all map tasks=140828\n","\t\tTotal vcore-milliseconds taken by all reduce tasks=42371\n","\tMap-Reduce Framework\n","\t\tCPU time spent (ms)=80450\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tFailed Shuffles=0\n","\t\tGC time elapsed (ms)=658\n","\t\tInput split bytes=304\n","\t\tMap input records=2987624\n","\t\tMap output bytes=38720700\n","\t\tMap output materialized bytes=44695960\n","\t\tMap output records=2987624\n","\t\tMerged Map outputs=2\n","\t\tPeak Map Physical memory (bytes)=248963072\n","\t\tPeak Map Virtual memory (bytes)=2527473664\n","\t\tPeak Reduce Physical memory (bytes)=194736128\n","\t\tPeak Reduce Virtual memory (bytes)=2535366656\n","\t\tPhysical memory (bytes) snapshot=622379008\n","\t\tReduce input groups=374785\n","\t\tReduce input records=2987624\n","\t\tReduce output records=374785\n","\t\tReduce shuffle bytes=44695960\n","\t\tShuffled Maps =2\n","\t\tSpilled Records=5975248\n","\t\tTotal committed heap usage (bytes)=432353280\n","\t\tVirtual memory (bytes) snapshot=7455559680\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","job output is in hdfs:///user/bdccuser/list_of_followees\n","Removing HDFS temp directory hdfs:///user/bdccuser/tmp/mrjob/task_2.bdccuser.20210611.174303.225147...\n","Removing temp directory /tmp/task_2.bdccuser.20210611.174303.225147...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gyVKalK9TSwq","outputId":"a4888b98-e3a7-4122-ee4d-c4cef212fa48"},"source":["!hdfs dfs -copyToLocal list_of_followees /home/bdccuser/notebooks/mapreduce/out/list_of_followees"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-06-11 20:45:38,325 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n"],"name":"stdout"}]}]}